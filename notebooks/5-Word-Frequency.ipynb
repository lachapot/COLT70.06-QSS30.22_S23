{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80ab2b47-bb8c-4ac8-9ed2-f40444d8df3c",
   "metadata": {},
   "source": [
    "# Word Frequency: Counting Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aca822-6a67-4d51-9556-c9eef340c801",
   "metadata": {},
   "source": [
    "## Counting word frequencies for a single text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086ae490-1d84-47b6-a13d-6bc237f0c419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the libraries we will need\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253a7601-4556-45fa-b1fd-32205490acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set path to our file\n",
    "text_file = 'soderberg-corpus/1897_Drizzle.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616daf0b-60d8-4215-979c-372d5b27e1b3",
   "metadata": {},
   "source": [
    "### Tokenizing: splitting your texts into units of analysis (in this case words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c35732-31f9-4dec-8f51-5f4e73598ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a tokenizing function\n",
    "\"\"\"This function keeps only words, no numbers.\n",
    "It lowcases\n",
    "splits at and removes anything that is not a \"word\" character\n",
    "(i.e. a letter or digit or underbar)\n",
    "so it will split at and remove whitspace and punctuation\n",
    "Then keeps only alphabetic characters \n",
    "(i.e. remove numbers) with .isalpha()\n",
    "\"\"\"\n",
    "\n",
    "def tokenize(text):\n",
    "    lowercase_text = text.lower()\n",
    "    split_words = re.split(r'\\W+', lowercase_text)\n",
    "    tokenized = [word for word in split_words if word.isalpha()]\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408c60b4-ea98-48fb-a370-2d87a67d8aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the file and tokenize it \n",
    "#(creates a list of all the words/tokens in all_words)\n",
    "with open(text_file, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "    all_words = tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9d9e7f-a817-402b-bc4c-24ec2a3fb56a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Print first twenty tokens in your list of tokens\n",
    "print(all_words[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76fc221-bcf0-47ef-9047-f5d804547eb0",
   "metadata": {},
   "source": [
    "### Unfiltered Most Frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67391824-9ac8-4205-b6af-8bc91a130f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to count the most frequent words\n",
    "#You can change the number of most frequent words in number_of_top_words variable\n",
    "def print_frequent_words(list_of_tokens):\n",
    "    words_tally = Counter(list_of_tokens)\n",
    "    number_of_top_words = 50\n",
    "    most_frequent_words = words_tally.most_common(number_of_top_words)\n",
    "    return most_frequent_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9dc653-326a-43c0-9ea6-dff02f34ade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the most frequent words\n",
    "#by calling the function on your list of tokens\n",
    "most_frequent = print_frequent_words(all_words)\n",
    "print(most_frequent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7378cc07-59df-4ad9-a07b-9b9030d47f3c",
   "metadata": {},
   "source": [
    "### Removing Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7986305-cd96-451e-a781-82850a4ce53a",
   "metadata": {},
   "source": [
    "To make the results more meaninful we can filter out words we don't want in our analyses by using a stopwords list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35049a5a-60ab-4681-91ce-4669165eaa5d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Getting the stopwords list from spaCy\n",
    "import spacy\n",
    "\n",
    "#Download the language model you're interested in \n",
    "#(this is for english)\n",
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4f1c85-527b-4167-959d-3ef755ee4fbc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load language model and stopwords list\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "stopwords = nlp.Defaults.stop_words\n",
    "sorted(list(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472095a2-893a-42d4-8517-5c006c0dacdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write out the spacy stopwords list to a txt file\n",
    "with open(\"custom-stopwords.txt\", \"a\") as file_object:\n",
    "    for word in sorted(list(stopwords)): \n",
    "        file_object.write(word + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b083b593-6991-4be4-851a-7bdebd55e59c",
   "metadata": {},
   "source": [
    "Open the file and look over the stopwords list. Are there any you want to keep or remove?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05840b12-3056-4523-832b-6b84d088c70b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define a function to remove stopwords from your list of tokens\n",
    "with open(\"custom-stopwords.txt\", \"r\") as file_object:\n",
    "    custom_stopwords = file_object.read()\n",
    "\n",
    "def remove_stopwords(list_of_tokens, stopwords):\n",
    "    return [token for token in list_of_tokens if token not in stopwords]\n",
    "\n",
    "all_words_no_stop = remove_stopwords(all_words, custom_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a105e6a-13e7-4b61-bc08-97f3c4635853",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Run word frequency function on your list of tokens with stopwords removed\n",
    "most_frequent_filtered = print_frequent_words(all_words_no_stop)\n",
    "print(most_frequent_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fa3372-6a80-43c2-a006-41f18cff4a43",
   "metadata": {},
   "source": [
    "Are there still words you want to add to your stopwords list? Open you stopwords file and add the words to the list, then run the two cells above again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9f356d-4f12-48ac-9977-282d1ff0d365",
   "metadata": {},
   "source": [
    "### Visualizing the most frequent words with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ab3bba-3782-4d80-8bb1-9a416e3a366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb8c1f7-10ed-46e0-85b6-94873e696c4b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Make dataframe of the frequent words in the text\n",
    "top_words_df = pd.DataFrame(most_frequent_filtered, columns = ['word', 'count'])\n",
    "top_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0c8ccd-56dd-4fab-b8e2-d3172596f261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write out as csv file (if you want to save the frequent words)\n",
    "#top_words_df.to_csv('drizzle_frequent.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558ed3bc-07f2-418d-b3ce-3e26ed5e2978",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Take top 10 most frequent words\n",
    "top_10_df = top_words_df[:10]\n",
    "top_10_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5f9b69-830a-4959-aeef-83305057be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create bar plot of top 10 frequent words\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2,7))\n",
    "figure = sns.barplot(data=top_10_df, x='count', y='word')\n",
    "\n",
    "# Save the figure\n",
    "#plt.savefig(\"drizzle_top_10.pdf\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ea8e94-e4cd-4e2e-b7f8-b656efc34327",
   "metadata": {},
   "source": [
    "## Counting the most frequent words across all the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098daef0-40be-46e5-a80a-e92dd1725d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  \n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dc3fe2-bdb5-4712-b8ee-534f8620de42",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Set path to your corpus\n",
    "#define that you want to analyze all .txt files in the directory\n",
    "directory_path = 'soderberg-corpus'\n",
    "text_files = glob.glob(f'{directory_path}/*.txt')\n",
    "print(text_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba2810-b250-4329-ae09-3abc6c9f9df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize the text files and append tokens to all_docs\n",
    "#This create a list of all the words from all the documents\n",
    "all_docs = []\n",
    "\n",
    "for filepath in text_files:\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        tokenized_text = tokenize(text)\n",
    "        all_docs.extend(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98658f50-fd9c-4844-b0c8-aa27560f6a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stopwords\n",
    "all_docs_no_stop = remove_stopwords(all_docs, custom_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0c4822-7d14-410e-b504-db766ad8f6cc",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Run word frequency function on your list of tokens with stopwords removed\n",
    "#These are the most frequent words from all the documents\n",
    "most_frequent_all_docs_filtered = print_frequent_words(all_docs_no_stop)\n",
    "print(most_frequent_all_docs_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d01bd5e-2925-405a-b13d-880ba1c11e68",
   "metadata": {},
   "source": [
    "## What are the most frequent words across all the short stories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ddb320-aceb-4253-968b-32b5d309b1b3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Read in the metdata csv to a pandas dataframe\n",
    "metadata_df = pd.read_csv('SoÌˆderberg-corpus-metadata.csv')\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326c0e47-cea0-4da0-834d-c34c2f7c6088",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Subset the dataframe to select just the short stories\n",
    "short_stories = metadata_df[metadata_df.genre == 'short story']\n",
    "short_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecb5ed3-0472-44cb-bb42-4c51e745c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the filenames for every short story\n",
    "short_stories_filenames = short_stories.filename.values\n",
    "short_stories_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e459c35e-7bf7-4be3-8d0f-4d907ad9c0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize the text files and append tokens to all_short_stories\n",
    "#This create a list of tokens for all the short stories\n",
    "all_short_stories = []\n",
    "\n",
    "for filepath in text_files:\n",
    "    for short_story in short_stories_filenames:\n",
    "        if short_story in filepath:\n",
    "            with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "                tokenized_text = tokenize(text)\n",
    "                all_short_stories.extend(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04058c05-ed6a-4d34-96c9-3138402109b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove stopwords\n",
    "all_words_ss_no_stop = remove_stopwords(all_short_stories, custom_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fc5c3a-8988-4513-9da4-6fff487f3250",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Count most frequent words for all short stories\n",
    "most_frequent_ss = print_frequent_words(all_words_ss_no_stop)\n",
    "print(most_frequent_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d433cd19-9f72-4f77-bb0b-ba0054b6eb4b",
   "metadata": {},
   "source": [
    "### Creating a barplot of most frequent words for short stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7461309-1464-4ad7-a385-c68b5ee0f278",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Make dataframe of the most frequent words from all short stories\n",
    "ss_top_words_df = pd.DataFrame(most_frequent_ss, columns = ['word', 'count'])\n",
    "\n",
    "ss_top_words_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0512168-5756-4366-b586-22e34a19ed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take top 10 most frequent words\n",
    "ss_top_10_df = ss_top_words_df[:10]\n",
    "ss_top_10_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d07868-b507-47e6-ba51-df763a233054",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create bar plots of top 10 most frequent words for all short stories\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2,7))\n",
    "figure = sns.barplot(data=ss_top_10_df, x='count', y='word')\n",
    "\n",
    "## Save the figure\n",
    "#plt.savefig(\"ss_top_10.pdf\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4a0f7f-115e-4ce0-af29-0d780ba7dabb",
   "metadata": {},
   "source": [
    "What if we want to count the most frequent words for novels? How would you go about doing that?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
