{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8832b84c-61cb-4b2e-a1a8-663f971680ce",
   "metadata": {},
   "source": [
    "# Collecting Texts from the Internet: Introduction to Webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58324c30-859c-427b-bdf7-5ed779fcca09",
   "metadata": {},
   "source": [
    "There is a huge amount of text and material available openly online, and there are ways to programmatically access and collect texts from websites. \n",
    "\n",
    "Webscraping saves you from having to manually navigate to each URL and copy/paste the text you want to use in a file, instead you can programmatically access the text data attached to every URL.\n",
    "\n",
    "In this notebook we’ll learn how to do this using the Python libraries `requests` and `BeautifulSoup`. \n",
    "\n",
    "(There are some more specialized libraries that exist. For example, the [Newspaper](https://newspaper.readthedocs.io/en/latest/) library is designed to collect online news articles)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55008ea3-84d6-433b-8df4-baa0fd0cdeb2",
   "metadata": {},
   "source": [
    "## Accessing web pages with Requests\n",
    "\n",
    "When you type in a URL in your search address bar, you’re sending an HTTP *request* for a web page, and the server which stores that web page will accordingly send back a *response*, some web page data that your browser will render."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94418c95-83c4-4a65-a9c1-c7a5920a31b0",
   "metadata": {},
   "source": [
    "![Request-Response](Request-Response.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de142148-b5df-40ad-8fc2-5e7b1a2621d5",
   "metadata": {},
   "source": [
    "We're using the library request to send out a request and store the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733111ac-55a6-4774-9f3b-67ab8d2dc40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fccb06-cb24-41a8-9af3-d7a4fcaa1c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the get method to get web page data from a specified URL\n",
    "#Store data in a variable called response\n",
    "response = requests.get(\"https://www.gutenberg.org/files/59227/59227-0.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd91791e-3afd-4d28-93b5-576a5789763f",
   "metadata": {},
   "source": [
    "We can check whether the `response` has been successful or not by looking at the [HTTP response code](https://developer.mozilla.org/en-US/docs/Web/HTTP/Status)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d35714-557c-4e19-84b3-bb13a048909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f801bdaa-475f-463c-b1f6-6a6d7337d513",
   "metadata": {},
   "source": [
    "“200” is a successful response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eade3f-6136-4041-8431-aa9ff442d4e3",
   "metadata": {},
   "source": [
    "If we modify the URL to an non-existent address, what response code do we get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bb17eb-e586-488e-8646-33eba5bbf054",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_response = requests.get(\"https://www.gutenberg.org/files/59227.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32966d31-5a9b-40bd-9313-416927cb6d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3505f8-387a-4112-853f-6af379596389",
   "metadata": {},
   "source": [
    "“404” is a common “Page Not Found” error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5063589e-4ae4-4358-b39c-fcaec6ac7af0",
   "metadata": {},
   "source": [
    "`Get` enables to store the request, but to actually get text data from the response we need to use `.text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc4d6e3-5742-4853-9714-8b58fd3ded4c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# store text data in variable html_string\n",
    "html_string = response.text\n",
    "print(html_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063682a7-babf-494d-b499-468906941a4a",
   "metadata": {},
   "source": [
    "## Extracting the text we want from HTML using BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4ae090-8f64-4544-9456-1d1dccd2654f",
   "metadata": {},
   "source": [
    "In the example above, we get all the text for Charlotte Gilman's *The Yellow Book* because the webpage itself is a .txt document: `https://www.gutenberg.org/files/59227/59227-0.txt` But not all webpages are like that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae67e68-1e18-4af6-bb88-205958255c85",
   "metadata": {},
   "source": [
    "For example, if we look at [The Dartmouth](https://www.thedartmouth.com/) homepage, the page seems to display text and images text, but there’s a lot more information beyond the text. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b692389f-efd1-4cf9-a3d7-b9f479b49ba2",
   "metadata": {},
   "source": [
    "If we do the same as before and convert our `response` into text, we can see there’s a lot more messy information compared to the Gilman URL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a518413-20e4-40f3-adfa-39d2ec88e00d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.get(\"https://www.thedartmouth.com/\")\n",
    "html_string = response.text\n",
    "print(html_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d3519a-fe53-4433-815e-21f501e5aec8",
   "metadata": {},
   "source": [
    "This messy information is in fact quite structured. Web pages are written in HTML, and we see is the HTML source of the webpage. If we learn how to read HTML, we can use the Python library `BeautifulSoup` to extract only the text we want from the pages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dff8a4-62f4-4cc6-9fe3-fef8456651ab",
   "metadata": {},
   "source": [
    "### Introduction to HTML\n",
    "\n",
    "Just like Markdown, HTML (which stands for HyperText Markup Language) is a way of writing web page documents. It uses different tags and labels to signal what kinds of element each part of page is (e.g headers, titles, body etc.) Often, particular parts of the page are signaled using an opening and closing tag. For example, a main header will be surrounded by surrounded by an opening tag: `<h1>` and a closing tag: `</h1>`. **We can use these HTML tags to identify the parts of the webpage we want to extract**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f97eb90-e892-4ea0-a830-391f5a126c30",
   "metadata": {},
   "source": [
    "**Reading HTML**\n",
    "\n",
    "Poet, programmer, and professor Allison Parrish has created a website to learn about HTML entitled [“Kittens and the TV Shows They Love.”](http://static.decontextualize.com/kittens.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f1f90f-4241-470f-a7c3-5d8193f2976e",
   "metadata": {},
   "source": [
    "As before, let’s get the response from the address and convert to text. Read over the output. Can you identify any labels and patterns in the labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc2f5a4-329d-443c-82f9-c7418b22a148",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.get(\"http://static.decontextualize.com/kittens.html\")\n",
    "html_string = response.text\n",
    "print(html_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327f8f9d-15c2-4ff8-9114-cdf81124f132",
   "metadata": {},
   "source": [
    "Here is a list of a few HTML tags: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0014d841-4f7e-4a3a-b3f1-a5d1c0b74518",
   "metadata": {},
   "source": [
    "![Html-tags.png](Html-tags.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c373f9-e7a7-4fa8-9694-6705a423807d",
   "metadata": {},
   "source": [
    "### Inspect HTML Elements in your Browser\n",
    "\n",
    "You can inspect webpages and identify the HTML elements you’re interested in using your Browser. When you are on a webpage you want to inspect, right click and select “Inspect”. Or got to “View” > “Inspect Elements”. You can also use the shortcut *control-shift-C* on Windows or *command-option-C* on macOS.\n",
    "\n",
    "The HTML elements will appear on the right and you can hover over and explore. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ebfbac-ada5-4e00-953b-2137179eb545",
   "metadata": {},
   "source": [
    "![Inspect-1.png](Inspect-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea75140-9b6a-407f-be4e-69450b998cdf",
   "metadata": {},
   "source": [
    "![Inspect-2.png](Inspect-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd14e1b-0fcd-4ca6-8ae9-3e2ef4e91e28",
   "metadata": {},
   "source": [
    "### Extracting elements from HTML using BeautifulSoup\n",
    "\n",
    "Now that we can request and get text data from webpages, and we can read and identify relevant labels from HTML, we can use the library `BeautifulSoup` to extract the parts of the page we are interested in. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a4142c-fb36-44d1-adb4-131c3f9a45d9",
   "metadata": {},
   "source": [
    "To make a BeautifulSoup document, we call `BeautifulSoup()` with two parameters: \n",
    "- the response we got from our HTTP request (that we've converted to text/string and stored at the variable `html_string`)\n",
    "- and the kind of parser that we want to use, which will always be `\"html.parser\"` for our purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240bd928-70a3-4d95-b365-f565c39d495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc79594-a368-472d-a730-565c7846eb09",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = requests.get(\"http://static.decontextualize.com/kittens.html\")\n",
    "html_string = response.text\n",
    "\n",
    "document = BeautifulSoup(html_string, \"html.parser\")\n",
    "\n",
    "document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328c46b8-1d4c-4b81-9bde-4c4cc415c6b1",
   "metadata": {},
   "source": [
    "We can use the `.find()` method to find and extract certain elements, such as a main header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3077202f-6c55-4cb6-a913-445e4f131a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "document.find(\"h1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8bd804-037d-4f95-9cf2-c52ff430e82d",
   "metadata": {},
   "source": [
    "If we want only the text contained between those tags, we can use `.text` to extract just the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9bfbd4-fd0f-48ed-93de-a87745aae0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "document.find(\"h1\").text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3066c2f-d4e5-4125-800d-cb0918a8cdba",
   "metadata": {},
   "source": [
    "You can also extract multiple HTML elements at a time with `.find_all()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b522d-8bef-4421-bd57-071eec25a5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "document.find_all(\"h2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b841327-be7b-48dc-8f6e-eb4a414ef347",
   "metadata": {},
   "outputs": [],
   "source": [
    "document.find_all(\"div\", attrs={\"class\": \"kitten\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d55cab8-fd7c-4c0c-82a5-de4d7d60c873",
   "metadata": {},
   "source": [
    "In order to extract text data from multiple HTML elements, we need a `for` loop and some list-building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e7ccb7-f931-48d7-a295-bdd82c0f8fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find all h2 headers in the document\n",
    "all_h2_headers = document.find_all(\"h2\")\n",
    "\n",
    "#Create an empty list called h2_headers.\n",
    "#Creat a for loop:\n",
    "#for each header in all_h2_headers, \n",
    "#we will grab the .text, \n",
    "#put it into a variable called header_contents, \n",
    "#then .append() it to our h2_headers list.\n",
    "h2_headers = []\n",
    "for header in all_h2_headers:\n",
    "    header_contents = header.text\n",
    "    h2_headers.append(header_contents)\n",
    "h2_headers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
